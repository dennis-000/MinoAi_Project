{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 01: Data Loading and Overview\n",
    "\n",
    "## Purpose\n",
    "This notebook serves as the initial exploration phase of our data science project. The goal is to:\n",
    "- Load the NYC Airbnb dataset\n",
    "- Understand the structure and composition of the data\n",
    "- Identify data types and initial quality issues\n",
    "- Generate summary statistics\n",
    "\n",
    "## Learning Objectives\n",
    "- Demonstrate systematic approach to exploring unknown datasets\n",
    "- Identify numerical and categorical features\n",
    "- Detect missing values and potential data quality issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load the Dataset\n",
    "\n",
    "We load the dataset from the `data/` directory. This dataset contains information about Airbnb listings in New York City."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/MinoAI_dataset.csv')\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of observations: {df.shape[0]:,}\")\n",
    "print(f\"Number of variables: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Initial Data Inspection\n",
    "\n",
    "### 3.1 First Few Rows\n",
    "Examining the first few rows helps us understand the structure and content of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Last Few Rows\n",
    "Checking the last rows ensures data consistency throughout the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last 5 rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Random Sample\n",
    "Viewing random samples provides a better overall picture of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 10 random rows\n",
    "df.sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Dataset Information\n",
    "\n",
    "### 4.1 Column Names and Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset information\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*80)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Column List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all columns\n",
    "print(\"Column Names:\")\n",
    "print(\"=\"*80)\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Data Type Classification\n",
    "\n",
    "Identifying numerical and categorical features is crucial for subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"NUMERICAL COLUMNS:\")\n",
    "print(\"=\"*80)\n",
    "for i, col in enumerate(numerical_cols, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(\"\\nCATEGORICAL COLUMNS:\")\n",
    "print(\"=\"*80)\n",
    "for i, col in enumerate(categorical_cols, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nTotal Numerical: {len(numerical_cols)}\")\n",
    "print(f\"Total Categorical: {len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Summary Statistics\n",
    "\n",
    "### 6.1 Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of numerical features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of categorical features\n",
    "df.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Missing Values Analysis\n",
    "\n",
    "Identifying missing values is critical for data cleaning in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "# Create a summary dataframe\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': missing_values.values,\n",
    "    'Missing_Percentage': missing_percentage.values\n",
    "})\n",
    "\n",
    "# Sort by missing count (descending)\n",
    "missing_summary = missing_summary.sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "# Display only columns with missing values\n",
    "print(\"MISSING VALUES SUMMARY:\")\n",
    "print(\"=\"*80)\n",
    "missing_summary[missing_summary['Missing_Count'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Visualize Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Filter columns with missing values\n",
    "cols_with_missing = missing_summary[missing_summary['Missing_Count'] > 0]\n",
    "\n",
    "if len(cols_with_missing) > 0:\n",
    "    plt.barh(cols_with_missing['Column'], cols_with_missing['Missing_Percentage'])\n",
    "    plt.xlabel('Missing Percentage (%)', fontsize=12)\n",
    "    plt.ylabel('Column Name', fontsize=12)\n",
    "    plt.title('Missing Values by Column', fontsize=14, fontweight='bold')\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add percentage labels\n",
    "    for i, (col, pct) in enumerate(zip(cols_with_missing['Column'], cols_with_missing['Missing_Percentage'])):\n",
    "        plt.text(pct + 0.5, i, f'{pct:.2f}%', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing values found in the dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Unique Values Analysis\n",
    "\n",
    "Understanding the cardinality of categorical features helps in feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze unique values for each column\n",
    "unique_summary = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Unique_Count': [df[col].nunique() for col in df.columns],\n",
    "    'Data_Type': df.dtypes.values\n",
    "})\n",
    "\n",
    "print(\"UNIQUE VALUES SUMMARY:\")\n",
    "print(\"=\"*80)\n",
    "unique_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Categorical Feature Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display unique values for key categorical columns\n",
    "key_categorical = ['neighbourhood_group', 'room_type']\n",
    "\n",
    "for col in key_categorical:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col.upper()}:\")\n",
    "        print(\"=\"*80)\n",
    "        print(df[col].value_counts())\n",
    "        print(f\"\\nUnique values: {df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Initial Observations and Insights\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "Based on our initial exploration, we can make the following observations:\n",
    "\n",
    "1. **Dataset Size**: The dataset contains approximately 49,000 Airbnb listings across New York City.\n",
    "\n",
    "2. **Features**: We have 16 variables including:\n",
    "   - Listing identifiers (id, name)\n",
    "   - Host information (host_id, host_name)\n",
    "   - Location data (neighbourhood_group, neighbourhood, latitude, longitude)\n",
    "   - Property characteristics (room_type, price, minimum_nights)\n",
    "   - Review metrics (number_of_reviews, last_review, reviews_per_month)\n",
    "   - Availability (availability_365)\n",
    "\n",
    "3. **Missing Values**: Several columns contain missing values, particularly:\n",
    "   - `last_review` and `reviews_per_month` (likely for listings with no reviews)\n",
    "   - `name` and `host_name` (some missing text data)\n",
    "\n",
    "4. **Data Types**: \n",
    "   - Numerical features: price, minimum_nights, number_of_reviews, etc.\n",
    "   - Categorical features: neighbourhood_group, room_type, etc.\n",
    "   - Text features: name, host_name\n",
    "\n",
    "5. **Potential Issues**:\n",
    "   - Date column (`last_review`) is stored as object/string, needs conversion\n",
    "   - Missing values need to be handled appropriately\n",
    "   - Potential outliers in price and other numerical features\n",
    "\n",
    "### Next Steps:\n",
    "In the next notebook (02_data_cleaning.ipynb), we will:\n",
    "- Handle missing values using multiple techniques (forward fill, backward fill, interpolation, mean imputation)\n",
    "- Convert data types where necessary\n",
    "- Check for and remove duplicates\n",
    "- Prepare the dataset for exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Save Summary Information\n",
    "\n",
    "We'll save key information for reference in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save column information\n",
    "print(\"Dataset Overview Summary:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total Rows: {df.shape[0]:,}\")\n",
    "print(f\"Total Columns: {df.shape[1]}\")\n",
    "print(f\"Numerical Columns: {len(numerical_cols)}\")\n",
    "print(f\"Categorical Columns: {len(categorical_cols)}\")\n",
    "print(f\"Columns with Missing Values: {(missing_values > 0).sum()}\")\n",
    "print(f\"Total Missing Values: {missing_values.sum():,}\")\n",
    "print(f\"Missing Data Percentage: {(missing_values.sum() / (df.shape[0] * df.shape[1]) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "\n",
    "This notebook has successfully:\n",
    "- ✅ Loaded the NYC Airbnb dataset\n",
    "- ✅ Examined the structure and composition of the data\n",
    "- ✅ Identified numerical and categorical features\n",
    "- ✅ Detected missing values and their distribution\n",
    "- ✅ Generated summary statistics\n",
    "- ✅ Documented initial observations\n",
    "\n",
    "The dataset is now ready for the data cleaning phase in the next notebook.\n",
    "\n",
    "---\n",
    "**Next Notebook**: [02_data_cleaning.ipynb](02_data_cleaning.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
